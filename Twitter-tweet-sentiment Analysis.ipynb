{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twitter Tweet Sentiment Analysis using Naive Bayes\n",
        "\n",
        "This notebook implements entity-level sentiment analysis using Naive Bayes classifier with Bag-of-Words (BoW) vectorization. The model predicts sentiment (Positive, Negative, Neutral) for tweets related to specific entities.\n",
        "\n",
        "## Dataset\n",
        "- Twitter training dataset with columns: ID, Entity, Sentiment, Tweet\n",
        "- Entities include companies, products, or people mentioned in tweets\n",
        "- Sentiments are labeled as Positive, Negative, or Neutral\n",
        "\n",
        "## Methodology\n",
        "1. Data preprocessing and cleaning\n",
        "2. Text vectorization using Bag-of-Words\n",
        "3. Naive Bayes classification\n",
        "4. Model evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkAALpAR1L9n"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "#  Entity-Level Sentiment Analysis using Naive Bayes (BoW)\n",
        "# ==============================\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer       # To convert text into numeric vectors (BoW)\n",
        "from sklearn.preprocessing import LabelEncoder                    # To convert text labels into numbers\n",
        "from sklearn.model_selection import train_test_split              # To split data into train/test sets\n",
        "from sklearn.naive_bayes import MultinomialNB                     # Naive Bayes classifier for text\n",
        "from sklearn.metrics import classification_report                 # To evaluate model performance\n",
        "\n",
        "# =========================================\n",
        "# 1. üì• Load and prepare the dataset\n",
        "# =========================================\n",
        "# The dataset has no headers by default, so we specify column names\n",
        "df = pd.read_csv(\"dataset/twitter_training.csv\", header=None)\n",
        "df.columns = [\"ID\", \"Entity\", \"Sentiment\", \"Tweet\"]\n",
        "\n",
        "# =========================================\n",
        "# 2.  Clean and combine 'Entity' with 'Tweet'\n",
        "# =========================================\n",
        "# Define a function to clean tweet text\n",
        "def clean_tweet(text):\n",
        "    if not isinstance(text, str):\n",
        "        return text  # Leave non-strings (like NaNs) untouched\n",
        "    text = re.sub(r'@\\w+', '', text)                             # Remove @mentions like @user123\n",
        "    text = re.sub(r'http\\S+|www.\\S+|pic.twitter\\S+', '', text)   # Remove URLs and Twitter image links\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()                     # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Combine the Entity name and Tweet for training (e.g., \"Apple : I love their products\")\n",
        "combined = (df[\"Entity\"] + \" : \" + df[\"Tweet\"]).apply(clean_tweet).dropna()\n",
        "\n",
        "# Also keep the matching Sentiment labels (ensures same indexes)\n",
        "labels = df[\"Sentiment\"].loc[combined.index]\n",
        "\n",
        "# =========================================\n",
        "# 3. Convert text to numerical features using Bag-of-Words\n",
        "# =========================================\n",
        "vectorizer = CountVectorizer()                     # Initialize BoW converter\n",
        "X_bow = vectorizer.fit_transform(combined)         # Convert text to vector format (sparse matrix)\n",
        "\n",
        "# =========================================\n",
        "# 4. üè∑Ô∏è Encode string labels (Positive, Negative, Neutral) as numbers\n",
        "# =========================================\n",
        "le = LabelEncoder()                                # Initialize label encoder\n",
        "y = le.fit_transform(labels)                       # Converts: ['Positive', 'Negative', ...] ‚Üí [2, 0, ...]\n",
        "\n",
        "# Print label classes for reference\n",
        "# print(le.classes_)   ‚Üí ['Negative' 'Neutral' 'Positive']\n",
        "\n",
        "# =========================================\n",
        "# 5.  Split into training and testing sets\n",
        "# =========================================\n",
        "# We use 80% data for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_bow, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# =========================================\n",
        "# 6.  Train Naive Bayes classifier\n",
        "# =========================================\n",
        "model = MultinomialNB()            # Suitable for text classification (word counts)\n",
        "model.fit(X_train, y_train)        # Train the model using BoW input and encoded labels\n",
        "\n",
        "# =========================================\n",
        "# 7.  Evaluate model performance\n",
        "# =========================================\n",
        "y_pred = model.predict(X_test)     # Predict sentiment for the test set\n",
        "\n",
        "# Show precision, recall, f1-score, and accuracy\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# =========================================\n",
        "# 8.  Predict sentiment for a new entity (no tweet)\n",
        "# =========================================\n",
        "entity_name = \"nvidia\"                                  # Example entity input\n",
        "test_vec = vectorizer.transform([entity_name + \" :\"])   # Format matches training input\n",
        "pred = model.predict(test_vec)                          # Predict sentiment\n",
        "print(f\"Sentiment for '{entity_name}': {le.inverse_transform(pred)[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results and Analysis\n",
        "\n",
        "The model combines entity names with tweet content to provide entity-specific sentiment analysis. This approach allows for more contextual sentiment prediction compared to general tweet sentiment analysis.\n",
        "\n",
        "### Key Features:\n",
        "- **Text Preprocessing**: Removes mentions, URLs, and extra whitespace\n",
        "- **Entity-Tweet Combination**: Concatenates entity and tweet for context\n",
        "- **Bag-of-Words Vectorization**: Converts text to numerical features\n",
        "- **Naive Bayes Classification**: Probabilistic approach suitable for text classification\n",
        "\n",
        "### Model Performance:\n",
        "The classification report shows precision, recall, and F1-scores for each sentiment class, providing insights into model effectiveness across different sentiment categories."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
